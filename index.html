<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>LAD: LoRA-Adapted Diffusion</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
    <style>
        body { font-family: 'Inter', sans-serif; max-width: 900px; margin: auto; line-height: 1.6; padding: 2rem; background-color: #ffffff; color: #333; }
        h1, h2, h3 { color: #222; font-weight: 600; }
        p { margin-bottom: 1rem; }
        a.button { display: inline-block; padding: 10px 18px; margin: 0.5rem 0.5rem 0.5rem 0; background-color: #f5f5f5; color: #333; border-radius: 6px; border: 1px solid #ccc; text-decoration: none; transition: background-color 0.3s; }
        a.button:hover { background-color: #e0e0e0; }
        iframe { border: 1px solid #ccc; border-radius: 8px; width: 100%; height: 500px; }
        table { border-collapse: collapse; width: 100%; margin-top: 1rem; }
        th, td { border: 1px solid #ccc; padding: 0.5rem; text-align: left; }
        code, pre { background: #f0f0f0; padding: 0.5em; border-radius: 4px; display: block; overflow-x: auto; }
        figure { text-align: center; margin: 2rem 0; }
        figcaption { font-size: 0.9rem; color: #666; margin-top: 0.5rem; }
    </style>
</head>
<body>

    <h1>LAD: LoRA-Adapted Denoiser</h1>

    <div style="text-align: center;">    
      <p><strong>Authors:</strong> Ruurd Kuiper<sup>1</sup>, Maarten van Smeden<sup>1</sup>, Lars de Groot<sup>1</sup>, Ayoub Bagheri<sup>2</sup></p>
      <p><sup>1</sup>UMC Utrecht &nbsp;&nbsp; <sup>2</sup>Utrecht University</p>
    
      <a href="https://huggingface.co/spaces/Ruurd/tini-lad" target="_blank" class="button" style="background-color: #3B82F6; color: white;">Simple Demo</a>
      <a href="https://huggingface.co/spaces/Ruurd/tini" target="_blank" class="button" style="background-color: #22C55E; color: white;">Extensive Demo</a>
      <a href="https://openreview.net/pdf?id=h8Zo1K6zpY" target="_blank" class="button" style="background-color: #8B5CF6; color: white;">Read the paper</a>
      <a href="https://www.youtube.com/watch?v=qy8saQXV_LM" target="_blank" class="button" style="background-color: #ff6347; color: white;">Watch the video</a>
      <a href="https://medium.com/ai-advances/think-before-you-speak-5611bcbbbd4c" target="_blank" class="button" style="background-color: #6B7280; color: white;">Read the Blogpost</a>
        <p id="contact" style="font-size: 0.7rem; color: #666; margin-top: 0.5rem;"></p>
        
        <script>
          const user = "r.j.a.kuiper";
          const domain = "umcutrecht.nl";
          const email = `${user}@${domain}`;
          const link = `<a href="mailto:${email}">${email}</a>`;
        
          document.getElementById("contact").innerHTML =
            `Our paper on LAD has been accepted at EMNLP 2025, and can already be found <a href="https://openreview.net/pdf?id=h8Zo1K6zpY" target="_blank">here</a></li>! For inquiries, contact us at ${link}.`;
        </script>
    </div>
    
    <h2>Demonstration</h2>
    <iframe src="https://ruurd-tini-lad.hf.space"></iframe>
    <p style="font-size: 0.9rem; color: #555; margin: 0.5rem auto 2rem; text-align: justify;">
        Interact with the LAD model above to see it in action. 
        The demo is running the <strong>LAD 8B Instruct</strong> model, which has been 
        fine-tuned to follow user instructions. Try turning off intermediate noising to experience <strong>diffusion without remasking</strong>.
        You can choose to add a short pause between iterations to visualize masked (red) and generated (green) tokens.
    </p>

    <h2>Core Innovations (TL;DR)</h2>
    <ol>
        <li><b>Efficient Adaptation:</b> Adapted for diffusion with <em>only several hours of training on a single GPU.</em></li>
        <li><b>Rapid Inference:</b> Often requires <em>less steps than number of output tokens</em> for simpler queries.</li>
        <li><b>Scalable test time compute:</b> Answer quality can be improved by <em>increasing iterations.</em></li>
        <li><b>Structural Denoising:</b> Combines masking and structural noising for <em>full-sequence refinement.</em></li>
        <li><b>Noiseless Refinement:</b> Enables iterative improvement of complete sequences <em>without remasking.</em></li>
    </ol>
        
    <h2>Motivation and Approach</h2>
    <p>Autoregressive models, while powerful, are constrained by a strict left-to-right generation process that limits efficiency and bidirectional reasoning. Diffusion-based models offer a promising, flexible alternative but have faced challenges in adapting to discrete text data. LAD (LoRA-Adapted Denoiser) was created to bridge this gap, offering a framework for non-autoregressive generation that is both flexible and efficient.</p>
    <p>We introduce a novel approach that adapts pretrained LLaMA<sup><a href="#ref1">1</a></sup> models for iterative, bidirectional sequence refinement. By repurposing these autoregressive models, LAD benefits from their extensive world knowledge while breaking free from their sequential decoding limitations. This is achieved without costly full-model retraining, making it a practical solution for developing advanced generative capabilities.</p>

    <h2>Visualizing the Denoising Process</h2>
    
    <div style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
      <figure style="flex: 1; min-width: 300px; max-width: 48%;">
        <img src="figure_lad_remask.png" alt="With Remasking"
             style="width: 100%; height: 300px; object-fit: contain;">
        <figcaption><strong>Left:</strong> Denoising with <em>remasking</em> after each step. Tokens are re-masked with decreasing frequency to allow iterative correction.</figcaption>
      </figure>
    
      <figure style="flex: 1; min-width: 300px; max-width: 48%;">
        <img src="figure_lad_noremask.png" alt="Without Remasking"
             style="width: 100%; height: 300px; object-fit: contain;">
        <figcaption><strong>Right:</strong> Denoising <em>without remasking</em>. Tokens are masked only at the beginning. However, our approach makes it possible for already unmasked tokens to still be refined.</figcaption>
      </figure>

        <p style="text-align: center; font-size: 0.9rem; color: #555; max-width: 700px; margin: 0rem auto 1rem;">
          <strong>Legend:</strong> Token shading reflects model confidence, ranging from red (low certainty) to green (high certainty). "MASK" refers to a masking token. Although not apparent from the right image, the denoising with remasking is also initialized with only "MASK" tokens.
        </p>

        <p>
          Unlike autoregressive models that require one step per token, LAD often converges in less iterations than its token output length. Both examples below reach coherent outputs in fewer steps than the sequence length. The no-remasking version converges in 16 steps, while the remasked version refines up to 32. Remasking enables better final quality and scalable compute, exemplified by the slight error in the final sentence of the version that does not use remasking.
        </p>

        
    </div>
    
    <h2>How LAD Works: Core Innovations</h2>
    <p>The core of LAD is its <strong>combined structural and masked training objective which enables flexible inference</strong>. We modify the standard 
        causal attention mechanism of the frozen LLaMA transformer backbone to be fully bidirectional, allowing the model to consider the entire 
        context of the sequence at once. On top of this frozen base, we train lightweight Low-Rank Adaptation (LoRA) adapters. This 
        parameter-efficient approach preserves the original model's knowledge while drastically reducing the computational resources 
        required for adaptation. <strong>By our knowledge, this is the first time it has been shown that an autoregressive model can be transformed for diffusive
        generation using solely LoRA finetuning.</strong>
    </p>

    <h2>Training and Efficiency</h2> 
    <p>The LAD 8B Instruct model was trained with an emphasis on extreme efficiency, which was accomplished by fine-tuning instead of training
        from scratch. We ran only 100,000 training iterations using a context length of 256 and a batch size of 8, which amounted to just 200 million 
        training tokens. For comparison, Metaâ€™s LLaMA 3 8B was trained on 15 trillion tokens, and comparable diffusion models trained from scratch such as LlaDa<sup><a href="#ref2">2</a></sup>,
        used 2.3 trillion tokens. This means LAD used <strong>just 0.001% and 0.008%</strong> of their respective token counts.
    </p> 
    <p>Training was completed in approximately <strong>10 hours on a single NVIDIA A100 (40GB) GPU.</strong> By employing a frozen Llama backbone with LoRA 
        adapters, LAD significantly lowers the barrier to entry for training powerful, non-autoregressive text models, avoiding 
        the high computational costs of training from scratch or full-parameter finetuning.
    </p>
            
    <h2>Preliminary Results</h2>
    
    <table>
      <tr><th>Benchmark</th><th>Score (% correct)</th></tr>
      <tr><td>ARC-Easy</td><td>88.5</td></tr>
      <tr><td>ARC-Challenge</td><td>81.0</td></tr>
      <tr><td>MMLU</td><td>60.5</td></tr>
      <tr><td>HellaSwag</td><td>70.0</td></tr>
    </table>
    
    <p><em>Note:</em> Scores were computed on a random 200-example subset per dataset. Full benchmark results will follow.</p>


    <h2>Citation</h2>
    <p>The first publication has been accepted at EMNLP 2025 and will be presented there. You can find the paper <a href="https://openreview.net/pdf?id=h8Zo1K6zpY" target="_blank"></a>here</li>, and you can cite it as:</p>
    <pre><code>@inproceedings{
    kuiper2025lad,
    title={{LAD}: Lo{RA}-Adapted Diffusion},
    author={Ruurd Jan Anthonius Kuiper and Maarten van Smeden and Lars de Groot and Bram van Es and Ayoub Bagheri},
    booktitle={The 2025 Conference on Empirical Methods in Natural Language Processing - System demonstrations},
    year={2025},
    url={https://openreview.net/forum?id=h8Zo1K6zpY}
}</code></pre>

    <p>We welcome feedback and collaboration as we continue to develop and evaluate LAD.</p>


<h2>References</h2>
<ol>
  <li id="ref1">Grattafiori, A., et al. (2024). <i>The Llama 3 Herd of Models</i>. <a href="https://arxiv.org/abs/2407.21783" target="_blank">arXiv:2407.21783</a>.</li>
  <li id="ref2">Nie, S., et al. (2025). <i>Large Language Diffusion Models</i>. <a href="https://arxiv.org/abs/2502.09992" target="_blank">arXiv:2502.09992</a>.</li>
</ol>
    
</body>
</html>
